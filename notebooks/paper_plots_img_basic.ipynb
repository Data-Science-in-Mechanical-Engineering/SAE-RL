{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import gymnasium\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from cycler import cycler\n",
    "from gymnasium.utils import seeding\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import DictConfig\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import __init__\n",
    "from scripts.train_rl import setup_environments\n",
    "from src.data import load\n",
    "from src.data.loading import ConstantRandomSampler\n",
    "from src.environments.utils import antialias\n",
    "from src.evaluation.utils import mm2in\n",
    "from src.metrics.transforms import AffineTransform\n",
    "from src.models.sae import assemble_sae\n",
    "from src.utils import Bunch, deflate, get_display, gl, inflate, print_cfg\n",
    "\n",
    "sys.modules['gym'] = gymnasium  # see [PR](https://github.com/DLR-RM/stable-baselines3/pull/780)\n",
    "from stable_baselines3 import SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Plotting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.prop_cycle': cycler('color', [\"#0173B2\", \"#DE8F05\", \"#029E73\", \"#D55E00\", \"#CC78BC\",\n",
    "                                        \"#CA9161\", \"#FBAFE4\", \"#949494\", \"#ECE133\", \"#56B4E9\"]),\n",
    "    'axes.titlepad': 4.0,\n",
    "    'axes.xmargin': 0.025,\n",
    "    'axes.ymargin': 0.025,\n",
    "    'axes.titlesize': 'medium',\n",
    "    'axes.labelpad': 1.0,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 8,\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': [r'\\usepackage{lmodern}'],\n",
    "    'grid.alpha': 0.1,\n",
    "    'grid.color': '#000000',\n",
    "    'legend.borderaxespad': 0.25,\n",
    "    'legend.borderpad': 0.0,\n",
    "    'legend.frameon': False,\n",
    "    'legend.columnspacing': 1.0,\n",
    "    'legend.handletextpad': 0.5,\n",
    "    'legend.handlelength': 1.0,\n",
    "    'lines.solid_capstyle': 'round',\n",
    "    'lines.solid_joinstyle': 'round',\n",
    "    'xtick.major.pad': 2.0,\n",
    "    'xtick.major.size': 2.0,\n",
    "    'xtick.minor.size': 0.0,\n",
    "    'ytick.major.pad': 2.0,\n",
    "    'ytick.major.size': 2.0,\n",
    "    'ytick.minor.size': 0.0,\n",
    "    'figure.constrained_layout.h_pad': 0.0,\n",
    "    'figure.constrained_layout.hspace': 0.0,\n",
    "    'figure.constrained_layout.use': True,\n",
    "    'figure.constrained_layout.w_pad': 0.0,\n",
    "    'figure.constrained_layout.wspace': 0.0\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path='../configs'):\n",
    "    rl_cfg = compose(config_name='train_rl', overrides=[\n",
    "        '+experiment=rl-feat',\n",
    "        'training.observation.keypoints=True',\n",
    "        'training.sae_checkpoint=logs/sae/panda_push_custom/basic+basic/2023-02-12--21-53-02--32879987/checkpoint_final.pth',\n",
    "        'training.sae_name=amber-thunder-15',\n",
    "        'training.sae_experiment=sae-basic',\n",
    "        'wandb=off',\n",
    "        'hydra=hush'\n",
    "    ])\n",
    "\n",
    "with initialize(version_base=None, config_path='../configs'):\n",
    "    sae_cfg = compose(config_name='train_sae', overrides=[\n",
    "        '+experiment=sae-basic',\n",
    "        'wandb=off',\n",
    "        'hydra=hush'\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Bunch(**torch.load('../logs/sae/panda_push_custom/basic+basic/2023-02-12--21-53-02--32879987/checkpoint_final.pth', map_location=gl.device))\n",
    "\n",
    "# reinstantiate model and optimizer\n",
    "model = assemble_sae(sae_cfg)\n",
    "model.load_state_dict(checkpoint.model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dataset_valid, = load(sae_cfg, valid=True)\n",
    "\n",
    "loader_valid = DataLoader(dataset_valid, sae_cfg.training.batch_size,\n",
    "                          sampler=ConstantRandomSampler(dataset_valid, sae_cfg.dataset.seed),\n",
    "                          shuffle=False, drop_last=True, num_workers=8, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()  # put model into evaluation state\n",
    "    track_fps = []  # feature points for tracking error computation\n",
    "    track_kps = []  # site coordinates for tracking error computation\n",
    "\n",
    "    # loop over validation batches\n",
    "    for batch, (inputs, _, sites) in enumerate(tqdm(loader_valid, leave=False)):\n",
    "\n",
    "        # move all data to GPU\n",
    "        inputs = inputs.to(gl.device)\n",
    "\n",
    "        # encoder pass to obtain feature points\n",
    "        fps = model.encoder(deflate(inputs))\n",
    "        feature_points = inflate(fps, len(inputs))\n",
    "\n",
    "        # storing fps and sites for first image of each snippet (avoiding duplicates)\n",
    "        track_fps.append(feature_points[:, 0])\n",
    "        track_kps.append(sites[:, 0])\n",
    "\n",
    "    track_fps = torch.cat(track_fps).to('cpu')\n",
    "    track_kps = torch.cat(track_kps).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sites = track_kps.shape[1]\n",
    "n_fps = track_fps.shape[1]\n",
    "\n",
    "pairwise_errors = torch.ones((n_sites, n_fps)) * np.inf\n",
    "regrs = [None] * n_sites\n",
    "closest_fps = [None] * n_sites\n",
    "\n",
    "# compute error for each pair of site and feature point\n",
    "for site in range(n_sites):\n",
    "    for fp in range(n_fps):\n",
    "        regr = AffineTransform()\n",
    "        regr.fit(track_fps[:, fp], track_kps[:, site])  # fit transformation\n",
    "        error = regr.mse(track_fps[:, fp], track_kps[:, site])\n",
    "        if torch.all(pairwise_errors[site, :] > error):\n",
    "            regrs[site] = regr\n",
    "            closest_fps[site] = fp\n",
    "        pairwise_errors[site, fp] = error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = SAC.load('../logs/rl/PandaPush-custom/2023-03-08--04-05-00--33793974/final_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = setup_environments(rl_cfg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "observations = []\n",
    "\n",
    "_ = venv.reset()\n",
    "_ = venv.seed(13)  # 5, 7, 11, 13, 28\n",
    "action = np.array([[0, 0, 0]])\n",
    "dones = np.array([False])\n",
    "\n",
    "while not np.any(dones):\n",
    "    obs, _, dones, info = venv.step(action)\n",
    "    if np.any(dones):\n",
    "        observations.append(info[0]['terminal_observation'])\n",
    "    else:\n",
    "        observations.append(obs.copy())\n",
    "    images.append(venv.render())\n",
    "    obs.pop('keypoints')\n",
    "    action, _ = policy.predict(obs, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(antialias(torch.tensor(images[0] / 255.0), 2), interpolation='none')\n",
    "kps = (np.stack([np.squeeze(observations[i]['keypoints']) for i in range(12)], axis=1) + 1) * 128\n",
    "fps_orig = np.stack([np.squeeze(observations[i]['feature_points']) for i in range(12)], axis=1)\n",
    "fps = (fps_orig + 1) * 128\n",
    "\n",
    "keypoints = [4]  # [0, 1, 4]\n",
    "\n",
    "for kp_idx in keypoints:\n",
    "    ax.plot(kps[kp_idx, :, 0], kps[kp_idx, :, 1], color='w', marker='.')\n",
    "for fp_idx in [closest_fps[k] for k in keypoints]:\n",
    "    ax.plot(fps[fp_idx, :, 1], fps[fp_idx, :, 0], color='C3', marker='.')\n",
    "    \n",
    "selected_regrs = [regrs[k] for k in keypoints]\n",
    "for i, fp_idx in enumerate([closest_fps[k] for k in keypoints]):\n",
    "    fps_t = (selected_regrs[i].transform(torch.tensor(fps_orig[fp_idx])) + 1) * 128\n",
    "    ax.plot(fps_t[:, 1], fps_t[:, 0], color='C0', marker='.')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "fig.set_size_inches(mm2in(122 * 0.49, 122 * 0.49))\n",
    "fig.savefig('../local/paper/img_basic_trajectories.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(antialias(torch.tensor(images[0] / 255.0), 2), interpolation='none')\n",
    "\n",
    "keypoints = [0, 1, 4]\n",
    "\n",
    "for kp_idx in keypoints:\n",
    "    ax.plot(kps[kp_idx, 0, 0], kps[kp_idx, 0, 1], color='w', marker='o')\n",
    "for fp_idx in [closest_fps[k] for k in keypoints]:\n",
    "    ax.plot(fps[fp_idx, 0, 1], fps[fp_idx, 0, 0], color='C3', marker='o')\n",
    "\n",
    "selected_regrs = [regrs[k] for k in keypoints]\n",
    "for i, fp_idx in enumerate([closest_fps[k] for k in keypoints]):\n",
    "    fps_t = (selected_regrs[i].transform(torch.tensor(fps_orig[fp_idx])) + 1) * 128\n",
    "    ax.plot(fps_t[0, 1], fps_t[0, 0], color='C0', marker='o')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "fig.set_size_inches(mm2in(122 * 0.49, 122 * 0.49))\n",
    "fig.savefig('../local/paper/img_basic_points.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-rl-BDjg6v1P",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
